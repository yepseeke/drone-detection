{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fa8990-a433-43a2-bd9d-46b4c3b73459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import scaleogram as scg\n",
    "\n",
    "import pytest\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a94a18f-3cc3-410c-88ce-19f25adeaa74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_signal(sound_path: str):\n",
    "    samplerate, x = wavfile.read(sound_path)\n",
    "    return samplerate, x\n",
    "\n",
    "def from_string_to_label(object_name:str):\n",
    "    label_map = {\n",
    "        'big_drone': 0,\n",
    "        'bird': 1,\n",
    "        'free_space': 2,\n",
    "        'human': 3,\n",
    "        'small_copter': 4\n",
    "    }\n",
    "    \n",
    "    return label_map.get(object_name, -1)\n",
    "\n",
    "def convert_gray2rgb(image):\n",
    "    width, height = image.shape\n",
    "    out = np.empty((width, height, 3), dtype=np.uint8)\n",
    "    out[:, :, 0] = image\n",
    "    out[:, :, 1] = image\n",
    "    out[:, :, 2] = image\n",
    "\n",
    "    return out\n",
    "\n",
    "def normalize_scaleogram(coefs):\n",
    "    min_coefs = np.min(coefs)\n",
    "    max_coefs = np.max(coefs)\n",
    "    normalized_coefs = np.int8(((coefs - min_coefs) / (max_coefs - min_coefs)) * 255)\n",
    "    \n",
    "    normalized_image = normalized_coefs.astype(np.uint8)\n",
    "\n",
    "    return normalized_image\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_scaleogram(sound_path, spectrum=None, wavelet=None, scales=None):\n",
    "    sample_rate, signal = get_signal(sound_path)\n",
    "\n",
    "    if not scales:\n",
    "        scales = scg.periods2scales(np.logspace(np.log10(2), np.log10(1000)), wavelet)\n",
    "\n",
    "    signal_length = signal.shape[0] / sample_rate\n",
    "    time = np.linspace(0, signal_length, signal.shape[0])\n",
    "    cwt = scg.CWT(time=time, signal=signal, scales=scales, wavelet=wavelet)\n",
    "\n",
    "    if spectrum == 'amp':\n",
    "        return np.abs(cwt.coefs), cwt.scales_freq\n",
    "    elif spectrum == 'real':\n",
    "        return np.real(cwt.coefs), cwt.scales_freq\n",
    "    elif spectrum == 'imag':\n",
    "        return np.imag(cwt.coefs), cwt.scales_freq\n",
    "    return cwt.coefs, cwt.scales_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da313425-d2fc-4ce6-bde4-6e98db1db002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "732ddbc2-36cd-424b-9a9a-52f7c134f6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = models.resnet18(pretrained=True) \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load('resnet18_cmor_model.pth'))\n",
    "\n",
    "device = torch.device(\"cuda:1\") \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b7b6627-2554-4b14-8a8b-187ca3903d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wavelet = 'cmor1.2-3'\n",
    "\n",
    "def test_audio(model, sound_path, transform, wavelet):\n",
    "    start = time.time()\n",
    "    coefs, _ = get_scaleogram(sound_path, spectrum='amp', wavelet=wavelet)\n",
    "    coefs = np.int32(coefs[len(coefs) // 4:, ::96])\n",
    "    coefs = normalize_scaleogram(coefs)\n",
    "    coefs_rgb = convert_gray2rgb(coefs)\n",
    "    end = time.time()\n",
    "    print(\"\\nCalculating scaleogram for: {:.3f} seconds\".format(end - start))\n",
    "    coefs_tensor = transform(coefs_rgb).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(coefs_tensor.to(device))\n",
    "        \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted_class = predicted.item()\n",
    "    \n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    return predicted_class, probabilities.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9abac1f-f182-4c39-ac37-477bbe866113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating scaleogram for: 0.151 seconds\n",
      "1 [4.9500555e-09 1.0000000e+00 3.6139938e-14 2.1430164e-08 4.0605416e-10]\n",
      "\n",
      "Processing for: 0.158 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.119 seconds\n",
      "4 [6.7559633e-08 3.5100004e-07 1.3896968e-10 4.2742151e-05 9.9995673e-01]\n",
      "\n",
      "Processing for: 0.126 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.119 seconds\n",
      "1 [5.0333835e-04 9.6132636e-01 4.4731816e-04 3.7719853e-02 3.1667378e-06]\n",
      "\n",
      "Processing for: 0.126 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.121 seconds\n",
      "3 [2.3857026e-06 1.0635946e-06 2.9985259e-08 9.9999559e-01 8.8750954e-07]\n",
      "\n",
      "Processing for: 0.130 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.120 seconds\n",
      "3 [2.6499245e-07 4.7847095e-08 3.7782797e-08 9.9999964e-01 2.9120978e-08]\n",
      "\n",
      "Processing for: 0.127 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.118 seconds\n",
      "2 [8.8950305e-09 5.9533656e-11 9.9999237e-01 1.6093721e-10 7.6353372e-06]\n",
      "\n",
      "Processing for: 0.125 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.117 seconds\n",
      "3 [4.2261627e-07 1.7533871e-08 4.2247277e-09 9.9999952e-01 1.5262950e-08]\n",
      "\n",
      "Processing for: 0.125 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.137 seconds\n",
      "4 [2.2326175e-12 7.7470563e-09 4.1049111e-18 3.9559942e-09 1.0000000e+00]\n",
      "\n",
      "Processing for: 0.148 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.149 seconds\n",
      "1 [1.7182572e-06 9.9998701e-01 4.4060136e-10 1.0580794e-05 6.7996797e-07]\n",
      "\n",
      "Processing for: 0.156 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.113 seconds\n",
      "0 [9.9999952e-01 4.3278484e-07 2.2037337e-15 1.1801380e-12 4.4848281e-10]\n",
      "\n",
      "Processing for: 0.119 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.114 seconds\n",
      "1 [8.6471648e-09 1.0000000e+00 1.2750547e-14 3.4276393e-09 1.4664558e-08]\n",
      "\n",
      "Processing for: 0.121 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.111 seconds\n",
      "2 [1.1156309e-09 2.5690042e-10 1.0000000e+00 1.8993986e-10 3.0674116e-08]\n",
      "\n",
      "Processing for: 0.118 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.111 seconds\n",
      "0 [1.0000000e+00 3.3642618e-20 4.0521692e-18 1.2154176e-22 1.6730685e-16]\n",
      "\n",
      "Processing for: 0.118 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.110 seconds\n",
      "4 [2.0107171e-20 1.2913001e-15 7.8534109e-29 2.9438876e-15 1.0000000e+00]\n",
      "\n",
      "Processing for: 0.118 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.111 seconds\n",
      "0 [1.0000000e+00 1.4133105e-17 2.2255263e-19 2.2197716e-17 7.7307585e-17]\n",
      "\n",
      "Processing for: 0.117 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.112 seconds\n",
      "1 [6.6034390e-06 9.9998987e-01 6.3023996e-11 2.8059692e-06 6.4567575e-07]\n",
      "\n",
      "Processing for: 0.118 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.112 seconds\n",
      "3 [8.3266104e-07 9.5738535e-08 3.0514311e-08 9.9999893e-01 6.2859236e-08]\n",
      "\n",
      "Processing for: 0.118 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.111 seconds\n",
      "4 [1.3984429e-19 2.0772886e-12 1.1431904e-31 1.0785384e-16 1.0000000e+00]\n",
      "\n",
      "Processing for: 0.118 seconds\n",
      "\n",
      "Calculating scaleogram for: 0.115 seconds\n",
      "4 [9.7701042e-23 1.2951438e-14 1.5866198e-36 5.6796528e-20 1.0000000e+00]\n",
      "\n",
      "Processing for: 0.122 seconds\n"
     ]
    }
   ],
   "source": [
    "test_data = os.path.join(os.getcwd(), 'test')\n",
    "for sound_data in os.listdir(test_data):\n",
    "    sound_path = os.path.join(test_data, sound_data)\n",
    "    start = time.time()\n",
    "    pred_class, probabilities = test_audio(model, sound_path, transform, wavelet)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(pred_class, probabilities)\n",
    "    print(\"\\nProcessing for: {:.3f} seconds\".format(end - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d05ea-5cc8-47ab-adcb-1eae604b3306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
